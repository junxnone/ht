## NLP

- 2017-06 Attention Is All You Need [[Paper](https://arxiv.org/pdf/1706.03762.pdf)] [[Code](https://nbviewer.jupyter.org/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb)] [[Note](https://github.com/junxnone/tech-io/issues/756)]
- 2018-10 **[BERT]**
- 2020-05 **[GPT3]**



## Vision

- 2020-05 **[DETR]** End-to-End Object Detection with Transformers [[Paper](https://arxiv.org/abs/2005.12872v3)] [[Code](https://github.com/facebookresearch/detr)] [[Note](notelink)] #ObjectDetection #Segmentation
- 2020-06 **[Linformer]** Linformer: Self-Attention with Linear Complexity[[Paper](https://arxiv.org/abs/2006.04768v3)] [[Code](https://github.com/lucidrains/linformer)] [[Note](notelink)] #Optimizition
- 2020-07 **[iGPT]** Generative Pretraining from Pixels[[Paper](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)] [[Code](https://github.com/openai/image-gpt)] [[Note](notelink)] #Classification
- 2020-09 **[Performer]** Rethinking Attention with Performers  [[paper](https://arxiv.org/pdf/2009.14794.pdf)] [[Code](https://github.com/google-research/google-research/tree/master/performer)] [[Note](https://github.com/junxnone/tech-io/issues/925)]
- 2020-10 **[ViT]** An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale [[Paper](https://arxiv.org/abs/2010.11929)] [[Code](https://github.com/google-research/vision_transformer)] [[Note](notelink)] #Classification
- 2020-10 **[Deformable DETR]** Deformable DETR: Deformable Transformers for End-to-End Object Detection(**ICLR**)[[paper](https://arxiv.org/abs/2010.04159)] [[code](https://github.com/fundamentalvision/Deformable-DETR)] [[Note](notelink)]
- 2020-11 **[UP-DETR]** UP-DETR: Unsupervised Pre-training for Object Detection with Transformers [[Paper](https://arxiv.org/abs/2011.09094)] [[Code](codelink)] [[Note](notelink)]
- 2020-11 **[LSTR]** End-to-end Lane Shape Prediction with Transformers [[Paper](https://arxiv.org/pdf/2011.04233.pdf)] [[Code](https://github.com/liuruijin17/LSTR)] [[Note](notelink)] #LaneDetection
- 2020-12 **[IPT]** Pre-Trained Image Processing Transformer [[Paper](https://arxiv.org/abs/2012.00364)] [[Code](codelink)] [[Note](notelink)] #denoising #super-resolution
- 2020-12 **[DeiT]** Training data-efficient image transformers & distillation through attention [[Paper](https://arxiv.org/abs/2012.12877)] [[Code](https://github.com/facebookresearch/deit)]  [[Note](https://github.com/junxnone/tech-io/issues/931)]
- 2021-01 **[BoTNet]** Bottleneck Transformers for Visual Recognition [[Paper](https://arxiv.org/abs/2101.11605)] [[Code](https://paperswithcode.com/paper/bottleneck-transformers-for-visual#code)]  [[Note](https://github.com/junxnone/tech-io/issues/929)]
- 2021-01 **[T2T-ViT]** Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet [[Paper](https://arxiv.org/abs/2101.11986)] [[Code](https://github.com/yitu-opensource/T2T-ViT)] [[Note](https://github.com/junxnone/tech-io/issues/928)]

## Survey

- 2021-01 A Survey on Visual Transformer [[Paper](https://arxiv.org/pdf/2012.12556.pdf)]  [[Note](https://github.com/junxnone/tech-io/issues/926)]
- 2021-01 Transformers in Vision: A Survey [[Paper](https://arxiv.org/pdf/2101.01169.pdf)]  [[Note](https://github.com/junxnone/tech-io/issues/927)]

